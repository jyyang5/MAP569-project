{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "py37",
   "display_name": "Python (py37)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP569 Project\n",
    "## Time: 17/04/2020\n",
    "## Name: Yelan MO, Jingyun YANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "# from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Id_Customer  Y  Number_Of_Dependant  Years_At_Residence  Years_At_Business  \\\n0         7440  0                  3.0                   1                1.0   \n1          573  0                  0.0                  12                2.0   \n\n   Nb_Of_Products Net_Annual_Income  \n0               1                36  \n1               1                18  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id_Customer</th>\n      <th>Y</th>\n      <th>Number_Of_Dependant</th>\n      <th>Years_At_Residence</th>\n      <th>Years_At_Business</th>\n      <th>Nb_Of_Products</th>\n      <th>Net_Annual_Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7440</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>573</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>12</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data_df = pd.read_csv('https://raw.githubusercontent.com/jyyang5/MAP569-project/master/CreditTraining.csv')\n",
    "label_df = data_df['Prod_Category'].tolist()\n",
    "\n",
    "# divide into categorical data and else as clean\n",
    "clean_df = data_df.select_dtypes(exclude=['object']).copy()\n",
    "cat_df = data_df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# replace comma with dot \n",
    "temp_list = []\n",
    "for ele in data_df['Net_Annual_Income'].tolist():\n",
    "  if type(ele) is not float:\n",
    "    temp_list.append(ele.replace(',','.'))\n",
    "  else:\n",
    "    temp_list.append(ele)\n",
    "\n",
    "clean_df['Net_Annual_Income'] = temp_list\n",
    "del cat_df['Net_Annual_Income']\n",
    "clean_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: there are categorical and timestamps that is not numeric.\n",
    "\n",
    "## 1.1. Deal with categorical data (timestamp data excluded)\n",
    "\n",
    "From all categorical datas ['Customer_Type', 'BirthDate', 'Customer_Open_Date', 'P_Client',\n",
    "       'Educational_Level', 'Marital_Status', 'Net_Annual_Income',\n",
    "       'Prod_Sub_Category', 'Prod_Decision_Date', 'Source',\n",
    "       'Type_Of_Residence', 'Prod_Closed_Date', 'Prod_Category']\n",
    "\n",
    "We first exclude ['BirthDate', 'Customer_Open_Date', 'Net_Annual_Income', 'Prod_Decision_Date']\n",
    "\n",
    "We use 0-1 encoding for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Non Existing Client    3369\nExisting Client        2011\nName: Customer_Type, dtype: int64\nNP_Client    4968\nP_Client      412\nName: P_Client, dtype: int64\nUniversity           4785\nMaster/PhD            522\nDiploma                58\nSecondary or Less      15\nName: Educational_Level, dtype: int64\nMarried      4206\nSingle       1046\nWidowed        64\nDivorced       63\nSeparated       1\nName: Marital_Status, dtype: int64\nC    4638\nG     624\nP     118\nName: Prod_Sub_Category, dtype: int64\nSales     4119\nBranch    1261\nName: Source, dtype: int64\nOwned       4791\nOld rent     323\nParents      179\nNew rent      83\nCompany        4\nName: Type_Of_Residence, dtype: int64\nB    3176\nD     670\nC     517\nK     265\nL     236\nG     188\nE     101\nH      79\nJ      71\nM      49\nA      19\nF       5\nI       4\nName: Prod_Category, dtype: int64\n"
    }
   ],
   "source": [
    "for name in ['Customer_Type', 'P_Client',\n",
    "            'Educational_Level', 'Marital_Status',\n",
    "            'Prod_Sub_Category', 'Source',\n",
    "            'Type_Of_Residence', 'Prod_Category']:\n",
    "        print(cat_df[name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'Customer_Type', 'P_Client', 'Source' all have just two types we therefore restrict ourselves to binary variable.\n",
    "\n",
    "$$\n",
    "Customer\\_Type = \n",
    " \\begin{cases}\n",
    "1& \\text{Existing Client} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\\\\n",
    "P\\_Client = \n",
    " \\begin{cases}\n",
    "1& \\text{P Client} \\\\\n",
    "0 & \\text{NP Client}\n",
    "\\end{cases} \\\\\n",
    "Source= \n",
    " \\begin{cases}\n",
    "1& \\text{Sales} \\\\\n",
    "0 & \\text{Brranch}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Id_Customer  Y  Number_Of_Dependant  Years_At_Residence  Years_At_Business  \\\n0         7440  0                  3.0                   1                1.0   \n1          573  0                  0.0                  12                2.0   \n\n   Nb_Of_Products Net_Annual_Income  Educational_Level_Diploma  \\\n0               1                36                          0   \n1               1                18                          0   \n\n   Educational_Level_Master/PhD  Educational_Level_Secondary or Less  ...  \\\n0                             0                                    0  ...   \n1                             0                                    0  ...   \n\n   Prod_Category_G  Prod_Category_H  Prod_Category_I  Prod_Category_J  \\\n0                0                0                0                0   \n1                1                0                0                0   \n\n   Prod_Category_K  Prod_Category_L  Prod_Category_M  Customer_Type  P_Client  \\\n0                0                0                0              0         1   \n1                0                0                0              1         0   \n\n   Source  \n0       0  \n1       0  \n\n[2 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id_Customer</th>\n      <th>Y</th>\n      <th>Number_Of_Dependant</th>\n      <th>Years_At_Residence</th>\n      <th>Years_At_Business</th>\n      <th>Nb_Of_Products</th>\n      <th>Net_Annual_Income</th>\n      <th>Educational_Level_Diploma</th>\n      <th>Educational_Level_Master/PhD</th>\n      <th>Educational_Level_Secondary or Less</th>\n      <th>...</th>\n      <th>Prod_Category_G</th>\n      <th>Prod_Category_H</th>\n      <th>Prod_Category_I</th>\n      <th>Prod_Category_J</th>\n      <th>Prod_Category_K</th>\n      <th>Prod_Category_L</th>\n      <th>Prod_Category_M</th>\n      <th>Customer_Type</th>\n      <th>P_Client</th>\n      <th>Source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7440</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>573</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>12</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 40 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# add categorical data [timestamp data not added]\n",
    "clean_df1 = clean_df.join(pd.get_dummies(cat_df[['Customer_Type', 'P_Client',\n",
    "                                                'Educational_Level', 'Marital_Status',\n",
    "                                                'Prod_Sub_Category', 'Source',\n",
    "                                                'Type_Of_Residence', 'Prod_Category']]))\n",
    "\n",
    "clean_df1['Customer_Type'] = clean_df1['Customer_Type_Existing Client']\n",
    "del clean_df1['Customer_Type_Existing Client']\n",
    "del clean_df1['Customer_Type_Non Existing Client']\n",
    "\n",
    "clean_df1['P_Client'] = clean_df1['P_Client_NP_Client']\n",
    "del clean_df1['P_Client_NP_Client']\n",
    "del clean_df1['P_Client_P_Client']\n",
    "\n",
    "clean_df1['Source'] = clean_df1['Source_Branch']\n",
    "del clean_df1['Source_Branch']\n",
    "del clean_df1['Source_Sales']\n",
    "\n",
    "\n",
    "clean_df1[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Deal with timestamps \n",
    "**Appraoches**: We use duration so that the variable is comparable \n",
    "\n",
    "['BirthDate', 'Customer_Open_Date', 'Net_Annual_Income', 'Prod_Decision_Date', 'Prod_Closed_Date']\n",
    "\n",
    "\n",
    "- `Birth_Duration = Now - BirthDate` ('BirthDate'): assuming there is a distribution of credibility, just started working -> less credit, worked for a long time but not close to retirement -> high credit) \n",
    "- `Customer_Open_Duration = Now - Customer_Open_Date` ('Customer_Open_Date'): usually longer the history is, the more royal the customer is\n",
    "- 'Prod_Closed_Date' - 'Prod_Decision_Date'\n",
    "    - length of the product?: if product closed \n",
    "    - `Prod_not_closed = (Prod_closed != nan)`: dummy variable if the product is closed 'Prod_not_closed' = 0 if closed\n",
    "    - `Prod_Decision_Duration = Now - Prod_Decision_Date`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([ 634, 1879, 1987, 2750, 5045, 5144]), array([1, 5, 3, 3, 1, 5]))"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# duration: birth - now\n",
    "temp_list = [(datetime.now().date() - datetime.strptime(datetime_str, '%d/%m/%Y').date()).days for datetime_str in cat_df['BirthDate'].tolist()]\n",
    "clean_df1['Birth_Duration'] = temp_list\n",
    "\n",
    "# duration: Customer_Open_Date\n",
    "temp_list = [(datetime.now().date() - datetime.strptime(datetime_str, '%d/%m/%Y').date()).days for datetime_str in cat_df['Customer_Open_Date'].tolist()]\n",
    "clean_df1['Customer_Open_Duration'] = temp_list\n",
    "\n",
    "# dummy var: product closed = 1\n",
    "temp_list = [int(type(ele) != float) for ele in cat_df['Prod_Closed_Date'].tolist()]\n",
    "clean_df1['Prod_not_closed'] = temp_list\n",
    "\n",
    "# duration: Prod_Decision_Date\n",
    "temp_list = [(datetime.now().date() - datetime.strptime(datetime_str, '%d/%m/%Y').date()).days for datetime_str in cat_df['Prod_Decision_Date'].tolist()]\n",
    "clean_df1['Prod_Decision_Duration'] = temp_list\n",
    "\n",
    "# convert to a list \n",
    "data_list = []\n",
    "labels = []\n",
    "for name in clean_df1.columns.values:\n",
    "    if name is 'Id_Customer':\n",
    "        pass\n",
    "    elif name is 'Y':\n",
    "        labels = clean_df1[name].tolist()\n",
    "    else:\n",
    "        data_list.append(clean_df1[name].tolist())\n",
    "\n",
    "data_list = np.transpose(data_list)\n",
    "data_list = np.array(data_list, dtype=np.float64)\n",
    "np.where(np.isnan(data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed to training and testing, we check if there is nan element\n",
    "\n",
    "Customers with nan \n",
    "- Years_At_Business\n",
    "    - Id_Customer = 398, 5882\t\n",
    "- Number_Of_Dependant\n",
    "    - Id_Customer = 8953, 9588\t\n",
    "- Net_Annual_Income\n",
    "    - Id_Customer = 9399, 9555\t\n",
    "\n",
    "## 1.3. Nan elements \n",
    "There are two usual approaches to deal with nan elements, the first one drops the data with nan, the second on the other hand replace the nan element. Since it is very likely that we may face future clients with unkown data (nan), so that we use the second approach to make the method proposed more general.\n",
    "\n",
    "- Median \n",
    "- Most frequent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Check done: ', True)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "clean_df2 = clean_df1.copy()\n",
    "\n",
    "for name in ['Number_Of_Dependant', 'Years_At_Business', 'Net_Annual_Income']:\n",
    "    temp_list = np.array(clean_df2[name].tolist(), dtype=np.float64)\n",
    "    temp_list[np.isnan(temp_list)] = np.median(temp_list[~np.isnan(temp_list)])\n",
    "    # print(sum(np.isnan(temp_list)))\n",
    "    clean_df2[name] = temp_list\n",
    "\n",
    "# convert to train mat \n",
    "data_list = []\n",
    "labels = []\n",
    "for name in clean_df2.columns.values:\n",
    "    if name == 'Id_Customer':\n",
    "        pass\n",
    "        \n",
    "    elif name is 'Y':\n",
    "        labels = clean_df2[name].tolist()\n",
    "    else:\n",
    "        data_list.append(clean_df2[name].tolist())\n",
    "\n",
    "data_list = np.transpose(data_list)\n",
    "data_list = np.array(data_list, dtype=np.float64)\n",
    "np.where(np.isnan(data_list))\n",
    "train_df = clean_df2.copy()\n",
    "del train_df['Y']\n",
    "del train_df['Id_Customer']\n",
    "'Check done: ', np.shape(train_df)== np.shape(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-----------all-----------\n0 4987\n1 393\npercentage of 1: 0.07304832713754647\n-----------train-----------\n0 3751\n1 284\npercentage of 1: 0.07038413878562577\n-----------test-----------\n0 1236\n1 109\npercentage of 1: 0.08104089219330855\n"
    }
   ],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_list, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# np.save('X_train.npy',X_train)\n",
    "# np.save('X_test.npy',X_test)\n",
    "# np.save('y_train.npy',y_train)\n",
    "# np.save('y_test.npy',y_test)\n",
    "\n",
    "print('-----------all-----------')\n",
    "for i in set(labels):\n",
    "    print(i,labels.count(i))\n",
    "print('percentage of 1:', labels.count(1)/len(labels))\n",
    "\n",
    "print('-----------train-----------')\n",
    "for i in set(labels):\n",
    "    print(i,y_train.count(i))\n",
    "print('percentage of 1:', y_train.count(1)/len(y_train))\n",
    "\n",
    "print('-----------test-----------')\n",
    "for i in set(labels):\n",
    "    print(i,y_test.count(i))\n",
    "print('percentage of 1:', y_test.count(1)/len(y_test))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to be unbalanced (two labels has a relative big difference in percentag), we first try without balancing the data.\n",
    "\n",
    "## 2.1. Evaluation metrics\n",
    "\n",
    "| \t\t|     same clusters|   different clusters|\n",
    "| :-------- | --------:| :------: |\n",
    "| same class    |   TP  |  FN |\n",
    "|different class|   FP  |  TN |\n",
    "- $P(precision) = \\frac{TP}{TP+FP}$ \n",
    "- $R(recall) = \\frac{TP}{TP+FN}$ \n",
    "- $F_{\\beta}= \\frac{(\\beta^2+1)PR}{\\beta^2P+R}$\n",
    "\n",
    "### Note: since label=1 means that the client has defaulted on its credit, which is something that we definately want to avoid, we focus on *R(recall)* (percentage of detected clients among all truly defaulted clients) . In order to taken into consideration the *P(precision)* (the percentage of true clients among all detected clients), we use the *F 0.5-score*, the * $F_\\beta$-score where $\\beta = 2$, as the evaluation of the model\n",
    "\n",
    "$\\color{red}{\\text{From now on, the precison, recall and F-2 score are referred to prediction with label=1}}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2.2. Primal Test with Basic Model: SVM, KNN & Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_metric(y_test, preds):\n",
    "    \"\"\" \n",
    "    print the classification report \n",
    "    \"\"\"\n",
    "    print('confusion matrix')\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    print('summary [label=1]')\n",
    "    beta = 2\n",
    "    res = precision_recall_fscore_support(y_test, preds, beta = beta, pos_label = 1, average = 'binary')\n",
    "    print(\"precision:{}\\nrecall:{}\\nsupport:{}\".format(round(res[0],3),round(res[1],3),res[3]))\n",
    "    print('-------')\n",
    "    print(\"accuracy:\",round(accuracy_score(y_test, preds),3))\n",
    "    print(\"F{}-score:{}\".format(beta,round(res[2],3)))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, preds, pos_label=2)\n",
    "    metrics.auc(fpr, tpr)\n",
    "\n",
    "def tests(X_train, y_train, X_test, y_test):\n",
    "    \"\"\" print the evaluation results of deterministic models\n",
    "    \"\"\"\n",
    "    # KNeighbors\n",
    "    neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    pred_KNN = neigh.predict(X_test)\n",
    "    print('----------------K-Neighbors-------------------')\n",
    "    eval_metric(y_test, pred_KNN)\n",
    "\n",
    "    # SVM\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred_SVM = clf.predict(X_test)\n",
    "    print('----------------SVM-------------------')\n",
    "    eval_metric(y_test, pred_SVM)\n",
    "    \n",
    "    #Decision Tree\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "    dt.fit(X_train, y_train)\n",
    "    pred_DT = dt.predict(X_test)\n",
    "    print('-----------------Decision Tree------------------')\n",
    "    eval_metric(y_test, pred_DT)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------K-Neighbors-------------------\nconfusion matrix\n[[1230    6]\n [ 107    2]]\nsummary [label=1]\nprecision:0.25\nrecall:0.018\nsupport:None\n-------\naccuracy: 0.916\nF2-score:0.023\n----------------SVM-------------------\nconfusion matrix\n[[1236    0]\n [ 109    0]]\nsummary [label=1]\nprecision:0.0\nrecall:0.0\nsupport:None\n-------\naccuracy: 0.919\nF2-score:0.0\n-----------------Decision Tree------------------\nconfusion matrix\n[[1179   57]\n [  56   53]]\nsummary [label=1]\nprecision:0.482\nrecall:0.486\nsupport:None\n-------\naccuracy: 0.916\nF2-score:0.485\n"
    }
   ],
   "source": [
    "tests(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The accuracy of the three basic models reaches 0.9, which is satisfaisant for other ML tasks. However, we can notice that the SVM and KNN models predict that all the labels are '0', thanks to the imbalance of the data, the accuracy is still high with this sort of prediction, but it is not what we want. This is one reason why we chose to focus on Recall, Precision and F-score instead of Accuracy.\n",
    "- The rebalancing of input data is necessary espacially for models such as SVM, KNN and LR \n",
    "- The F2-score of Decision Tree reaches 0.47 with imbalanced data, this shows that the Decision Tree, as well as random forest, which will be used in the next part, could work well on imbalanced data.\n",
    "\n",
    "## 2.3. Balance data\n",
    "In Section 2.2, we did some experiments but find that even if the overall accurancy is high, the prediction results of clients with label=1 is not good. Especially with classifiers like SVM, the class with more samples (majority class) is favoured. We therefore resample the minority class to balance the train data and see how the result might improve. Since the size of the minority class is very small, we w.l.o.g. use Upsampling.   \n",
    "\n",
    "# 3. Encapsulation \n",
    "We combine all mentioned, add a few more functionalities and create the class below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Credit_predictor():\n",
    "    def __init__(self,path):\n",
    "        \"\"\"\n",
    "        read the data\n",
    "        \"\"\"\n",
    "        self.raw_data = pd.read_csv(path)\n",
    "        self.clean_df = self.raw_data.select_dtypes(exclude=['object']).copy()\n",
    "        self.cat_df = self.raw_data.select_dtypes(include=['object']).copy()\n",
    "        # categorical data \n",
    "        self.cates = ['Customer_Type', 'P_Client',\n",
    "            'Educational_Level', 'Marital_Status',\n",
    "            'Prod_Sub_Category', 'Source',\n",
    "            'Type_Of_Residence', 'Prod_Category']\n",
    "        # all timestamp data \n",
    "        self.date_trans_set = {'Birth_Duration':'BirthDate',\n",
    "             'Customer_Open_Duration':'Customer_Open_Date',\n",
    "             'Prod_Decision_Duration':'Prod_Decision_Date'}\n",
    "\n",
    "        self.data_preprocessing_0()\n",
    "        self.data_preprocessing_simple()\n",
    "        self.data_preprocessing_onehot()\n",
    "\n",
    "        # one-hot\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_dataset(self.data_oh)\n",
    "        # one-hot [balanced]\n",
    "        self.X_train_b, self.X_test_b, self.y_train_b, self.y_test_b = self.split_dataset_4_imbal(self.data_oh)\n",
    "        # categorical -> 0:n_classes-1\n",
    "        self.X_train_t, self.X_test_t, self.y_train_t, self.y_test_t = self.split_dataset(self.data_simple)\n",
    "        # categorical -> 0:n_classes-1 [balanced]\n",
    "        self.X_train_tb, self.X_test_tb, self.y_train_tb, self.y_test_tb = self.split_dataset_4_imbal(self.data_simple)\t\n",
    "        \n",
    "        \n",
    "    def data_preprocessing_0(self):\n",
    "        \"\"\"\n",
    "        seperate the data into numerical set and categorical set\n",
    "        \"\"\"\n",
    "        self.clean_df = self.raw_data.select_dtypes(exclude=['object']).copy()\n",
    "        self.cat_df = self.raw_data.select_dtypes(include=['object']).copy()\n",
    "        temp_list = []\n",
    "        # convert value from comma to dot \n",
    "        for ele in self.raw_data['Net_Annual_Income'].tolist():\n",
    "            if type(ele) is not float:\n",
    "                temp_list.append(ele.replace(',','.'))\n",
    "            else:\n",
    "                temp_list.append(ele)\n",
    "        self.clean_df['Net_Annual_Income'] = temp_list\n",
    "        del self.cat_df['Net_Annual_Income']\n",
    "        self.dates_transformer()\n",
    "        \n",
    "    def dates_transformer(self):\n",
    "        \"\"\"\n",
    "        processing for the date\n",
    "        \"\"\"\n",
    "        # convert timestamp to duration: now - timestamp \n",
    "        for i in self.date_trans_set:\n",
    "            temp_list = [(datetime.now().date() - datetime.strptime(datetime_str, '%d/%m/%Y').date()).days for datetime_str in self.cat_df[self.date_trans_set[i]].tolist()]\n",
    "            self.clean_df[i] = temp_list\n",
    "            del self.cat_df[self.date_trans_set[i]]\n",
    "        # indicator whether product is closed \n",
    "        temp_list = [int(type(ele) != float) for ele in self.cat_df['Prod_Closed_Date'].tolist()]\n",
    "        self.clean_df['Prod_not_closed'] = temp_list\n",
    "        del self.cat_df['Prod_Closed_Date']\n",
    "\n",
    "    def data_preprocessing_simple(self):\n",
    "        self.data_simple = self.clean_df.copy()\n",
    "        for i in self.cates:\n",
    "            labelencoder = LabelEncoder()\n",
    "            labelencoder.fit(self.cat_df[i])\n",
    "            self.data_simple[i] = labelencoder.transform(self.cat_df[i])\n",
    "        \n",
    "    def data_preprocessing_onehot(self):\n",
    "        binary = ['Customer_Type', 'P_Client', 'Source']\n",
    "        no_binary = [i for i in self.cates if i not in binary]\n",
    "        self.data_oh = self.clean_df.copy()\n",
    "        for i in binary:\n",
    "            labelencoder = LabelEncoder()\n",
    "            labelencoder.fit(self.cat_df[i])\n",
    "            \"\"\"\n",
    "            To see the representation of the labels : list(labelencoder.classes_)\n",
    "            \"\"\"\n",
    "            self.data_oh[i] = labelencoder.transform(self.cat_df[i])\n",
    "        self.data_oh = self.data_oh.join(pd.get_dummies(self.cat_df[no_binary]))\n",
    "        \n",
    "    def split_dataset(self,dataset):\n",
    "        X = dataset.drop('Y',axis = 1)\n",
    "        Y = dataset.Y\n",
    "        try:\n",
    "            imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "            imp_mean.fit(X)\n",
    "        except:\n",
    "            imp_mean = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "            imp_mean.fit(X)\n",
    "        '''\n",
    "        SimpleImputer:\n",
    "        strategy : mean, median, most_frequent, constant\n",
    "        '''\n",
    "        X_imputed = imp_mean.transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_imputed, Y, test_size=0.25, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def split_dataset_4_imbal(self,dataset):\n",
    "        X_train, X_test, y_train, y_test = self.split_dataset(dataset)\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "   #     ros = RandomOverSampler(random_state=0)\n",
    "   #     X_test, y_test = ros.fit_resample(X_test, y_test)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    \n",
    "    def convert_labels(self,labels):\n",
    "        \"\"\" \n",
    "        convert the input (0/1) labels to what is needed \n",
    "        return a binary label sequence \n",
    "        \"\"\"\n",
    "        labels = np.array(labels)\n",
    "        if sum(labels) > len(labels)/2:\n",
    "            labels[labels==1] = -1\n",
    "            labels[labels==0] = 1\n",
    "            labels[labels==-1] = 0\n",
    "        return labels\n",
    "\n",
    "    def eval_metric(self,y_test, preds):\n",
    "        \"\"\" \n",
    "        print the classification report \n",
    "        \"\"\"\n",
    "        print('confusion matrix')\n",
    "        print(confusion_matrix(y_test, preds))\n",
    "        print('--summary[label=1]--')\n",
    "     #   print('summary')\n",
    "        beta = 2\n",
    "        res = precision_recall_fscore_support(y_test, preds, beta = beta, pos_label = 1, average = 'binary')\n",
    "        print(\"precision:{}\\nrecall:{}\\nsupport:{}\".format(round(res[0],3),round(res[1],3),res[3]))\n",
    "        print('--------------------')\n",
    "        print(\"accuracy:\",round(accuracy_score(y_test, preds),3))\n",
    "        print(\"F{}-score:{}\".format(beta,round(res[2],3)))\n",
    "        print(\"\\n\")\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, preds, pos_label=2)\n",
    "        metrics.auc(fpr, tpr)   \n",
    "\n",
    "            \n",
    "    def model_eval(self, model, getPred = False, Normalize = False):\n",
    "        \"\"\"\n",
    "        print the evaluation result of the model with the Cp object \n",
    "\n",
    "        if getPred is True return prediction sequence\n",
    "        \"\"\"\n",
    "        # self.data_preprocessing_0()\n",
    "        # self.data_preprocessing_simple()\n",
    "        # self.data_preprocessing_onehot()\n",
    "        \n",
    "        if Normalize:\n",
    "            X_train = normalize(X_train, norm='l2')\n",
    "            X_test = normalize(X_test, norm='l2')\n",
    "            \n",
    "        print('----------------one-hot-------------------')\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        pred_y = model.predict(self.X_test)\n",
    "        self.eval_metric(self.y_test, pred_y)\n",
    "        print('----------------one-hot[balanced]-------------------')\n",
    "        model.fit(self.X_train_b, self.y_train_b)\n",
    "        pred_y_b = model.predict(self.X_test_b)\n",
    "        self.eval_metric(self.y_test_b, pred_y_b)\n",
    "        print('----------------0:n_classes-1-------------------')\n",
    "        model.fit(self.X_train_t, self.y_train_t)\n",
    "        pred_y_t = model.predict(self.X_test_t)\n",
    "        Cp.eval_metric(self.y_test_t, pred_y_t)\n",
    "        print('----------------0:n_classes-1[balanced]-------------------')\n",
    "        model.fit(self.X_train_tb, self.y_train_tb)\n",
    "        pred_y_tb = model.predict(self.X_test_tb)\n",
    "        Cp.eval_metric(self.y_test_tb, pred_y_tb)\n",
    "        \n",
    "        if getPred is True:\n",
    "            return pred_y, pred_y_b, pred_y_t, pred_y_tb\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'CreditTraining.csv'\n",
    "Cp = Credit_predictor(path)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Model selection \n",
    "### 3.1.1 LogisticRegression\n",
    "The *liblinear* method is chosen as it applies a coordinate descent (CD) algorithm, which performs better in a categarical data.\n",
    "\n",
    "The result of this model shows that the resampling of the data affect much the result for Logistic regression, in particular the *precision*, *recall*, and *F2-score*. Weather using onehot embedding or not does not affect much the result, which is the same case for all the other tests.\n",
    "\n",
    "The Logistic Regression Model reaches satisfactory recall and F2 score with balanced data, but low precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------one-hot-------------------\nconfusion matrix\n[[1233    3]\n [  96   13]]\n--summary[label=1]--\nprecision:0.812\nrecall:0.119\nsupport:None\n--------------------\naccuracy: 0.926\nF2-score:0.144\n\n\n----------------one-hot[balanced]-------------------\nconfusion matrix\n[[1110  126]\n [  16   93]]\n--summary[label=1]--\nprecision:0.425\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.894\nF2-score:0.71\n\n\n----------------0:n_classes-1-------------------\nconfusion matrix\n[[1226   10]\n [  89   20]]\n--summary[label=1]--\nprecision:0.667\nrecall:0.183\nsupport:None\n--------------------\naccuracy: 0.926\nF2-score:0.215\n\n\n----------------0:n_classes-1[balanced]-------------------\nconfusion matrix\n[[1112  124]\n [  16   93]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.896\nF2-score:0.712\n\n\n"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr_pred_y, lr_pred_y_b, lr_pred_y_t, lr_pred_y_tb = Cp.model_eval(lr,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Random Forest \n",
    "The rebalancing of the data affects not that much the *precision*, *recall*, and *F2-score* as Logistic Regression. Still, we can observe that the resampling could augment the *recall* and *F2-score*, but sacrifice the *precision*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------one-hot-------------------\nconfusion matrix\n[[1228    8]\n [  76   33]]\n--summary[label=1]--\nprecision:0.805\nrecall:0.303\nsupport:None\n--------------------\naccuracy: 0.938\nF2-score:0.346\n\n\n----------------one-hot[balanced]-------------------\nconfusion matrix\n[[1205   31]\n [  60   49]]\n--summary[label=1]--\nprecision:0.612\nrecall:0.45\nsupport:None\n--------------------\naccuracy: 0.932\nF2-score:0.475\n\n\n----------------0:n_classes-1-------------------\nconfusion matrix\n[[1222   14]\n [  69   40]]\n--summary[label=1]--\nprecision:0.741\nrecall:0.367\nsupport:None\n--------------------\naccuracy: 0.938\nF2-score:0.408\n\n\n----------------0:n_classes-1[balanced]-------------------\nconfusion matrix\n[[1197   39]\n [  57   52]]\n--summary[label=1]--\nprecision:0.571\nrecall:0.477\nsupport:None\n--------------------\naccuracy: 0.929\nF2-score:0.493\n\n\n"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=100)\n",
    "rfc_pred_y, rfc_pred_y_b, rfc_pred_y_t, rfc_pred_y_tb = Cp.model_eval(rfc, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. SVM\n",
    "The linear kernel is applied, as it gives the best result for SVM, but the calculation time is sacrified. The normalization of the data does not affect much the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------one-hot-------------------\nconfusion matrix\n[[1236    0]\n [ 107    2]]\n--summary[label=1]--\nprecision:1.0\nrecall:0.018\nsupport:None\n--------------------\naccuracy: 0.92\nF2-score:0.023\n\n\n----------------one-hot[balanced]-------------------\nconfusion matrix\n[[818 418]\n [ 12  97]]\n--summary[label=1]--\nprecision:0.188\nrecall:0.89\nsupport:None\n--------------------\naccuracy: 0.68\nF2-score:0.51\n\n\n----------------0:n_classes-1-------------------\nconfusion matrix\n[[1235    1]\n [ 101    8]]\n--summary[label=1]--\nprecision:0.889\nrecall:0.073\nsupport:None\n--------------------\naccuracy: 0.924\nF2-score:0.09\n\n\n----------------0:n_classes-1[balanced]-------------------\nconfusion matrix\n[[911 325]\n [ 15  94]]\n--summary[label=1]--\nprecision:0.224\nrecall:0.862\nsupport:None\n--------------------\naccuracy: 0.747\nF2-score:0.55\n\n\n"
    }
   ],
   "source": [
    "clf = SVC(gamma='auto',kernel='linear')\n",
    "clf_pred_y, clf_pred_y_b, clf_pred_y_t, clf_pred_y_tb = Cp.model_eval(clf, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. LDA\n",
    "The LDA(Linear Discriminant Analysis) model gives high *recall* but comparatively low *precision*, the rebalancing of the data and the use of onehot embedding does not affect much the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------one-hot-------------------\nconfusion matrix\n[[1134  102]\n [  21   88]]\n--summary[label=1]--\nprecision:0.463\nrecall:0.807\nsupport:None\n--------------------\naccuracy: 0.909\nF2-score:0.703\n\n\n----------------one-hot[balanced]-------------------\nconfusion matrix\n[[1107  129]\n [  13   96]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.894\nF2-score:0.726\n\n\n----------------0:n_classes-1-------------------\nconfusion matrix\n[[1124  112]\n [  18   91]]\n--summary[label=1]--\nprecision:0.448\nrecall:0.835\nsupport:None\n--------------------\naccuracy: 0.903\nF2-score:0.712\n\n\n----------------0:n_classes-1[balanced]-------------------\nconfusion matrix\n[[1108  128]\n [  13   96]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.727\n\n\n"
    }
   ],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA_pred_y, LDA_pred_y_b, LDA_pred_y_t, LDA_pred_y_tb = Cp.model_eval(LDA, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. XGBoost \n",
    "For XGBoost, resampling seems to improve a lot regarding the recall while sacrifice a little of the precision, the result after resampling is similar to what LDA achieved. Through experiments changing objective and evaluation metric do not seem to have a huge difference.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "----------------one-hot-------------------\nconfusion matrix\n[[1219   17]\n [  83   26]]\n--summary[label=1]--\nprecision:0.605\nrecall:0.239\nsupport:None\n--------------------\naccuracy: 0.926\nF2-score:0.271\n\n\n----------------one-hot[balanced]-------------------\nconfusion matrix\n[[1115  121]\n [  15   94]]\n--summary[label=1]--\nprecision:0.437\nrecall:0.862\nsupport:None\n--------------------\naccuracy: 0.899\nF2-score:0.722\n\n\n----------------0:n_classes-1-------------------\nconfusion matrix\n[[1220   16]\n [  76   33]]\n--summary[label=1]--\nprecision:0.673\nrecall:0.303\nsupport:None\n--------------------\naccuracy: 0.932\nF2-score:0.34\n\n\n----------------0:n_classes-1[balanced]-------------------\nconfusion matrix\n[[1111  125]\n [  16   93]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.711\n\n\n"
    }
   ],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='reg:logistic')\n",
    "xg_pred_y, xg_pred_y_b, xg_pred_y_t, xg_pred_y_tb = Cp.model_eval(xg_reg, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Observations**\n",
    "- Balancing the data indeed helps to improve the model performance \n",
    "- We **select logistiRegression, LDA, and XGBoost given their $R_{\\text{label=1}}$ around 0.85, $F1_{\\text{label=1}} \\approx 0.72$, $P_{\\text{label=1}}$ around 0.42 using the two balanced data.**\n",
    "\n",
    "# 4. Voting  \n",
    "\n",
    "In this section, we propose two voting methods that utilize the predictions of several models and hopes it would maximize the information obatined so far.\n",
    "- Improve precision of predicted defaulted\n",
    "- Improve coverage of truly defaulted\n",
    "\n",
    "## 4.1. Minimize innocent (Improve precision of predicted defaulted)\n",
    "\n",
    "Since we have three models **logistiRegression, LDA, and XGBoost** using balanced data have $R_{\\text{label=1}}$ around 0.85 meaning most of the defaulted customers are detected (which we think is a **relative good coverage**).\n",
    "\n",
    "But $\\text{label=1} \\approx 0.42$ , meaning more than half of the predicted is not defaulted, and it would be costly to do a thorough investigation of the users so we want to **minimize those innocent but detected**.   \n",
    "\n",
    "With 3 predictions from 3 individual parties, we want to extract the mutual information and believing that if one client is predictd defaulted by all parties then there is a larger probability that the one is defaulted compared with (1/3 of the parties voted so). And of course, we might lose some covergae. **We try taking a logical AND to do this**.\n",
    "\n",
    "**Essentially, we are doing a voting by setting the weight to be 100% iff. all parties vote 1, ensuring that the number of inocent client is minimized**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "confusion matrix\n[[1118  118]\n [  17   92]]\n--summary[label=1]--\nprecision:0.438\nrecall:0.844\nsupport:None\n--------------------\naccuracy: 0.9\nF2-score:0.712\n\n\n"
    }
   ],
   "source": [
    "Cp.eval_metric(Cp.y_test_tb, LDA_pred_y_tb & xg_pred_y_tb & lr_pred_y_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.        , 0.01189591, 0.00669145],\n       [0.01189591, 0.        , 0.00966543],\n       [0.00669145, 0.00966543, 0.        ]])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "parties_pred_mat = [LDA_pred_y_tb, xg_pred_y_tb, lr_pred_y_tb]\n",
    "distance.cdist(parties_pred_mat, parties_pred_mat, 'hamming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the *Minimize innocent* voting mechanism fail to improve a $P_{\\text{label=1}}$ a lot is largely due to the percentage of shared information is dominant for all three parties (around 1% difference).\n",
    "\n",
    "## 4.2. Add trustworthy information ( Improve coverage of truly defaulted)\n",
    "\n",
    "We use one of the three parties as a base (with good covergae) and then we add prediction by party with high $P_{\\text{label=1}}$ but possibly low coverage ($R_{\\text{label=1}}$), so as to improve precison and recall at the same time.\n",
    "\n",
    "**Essentially, we are doing a voting by setting the weight of trustworthy party to 100%, meaning once they vote 1, the client is 1 in prediction.**\n",
    "\n",
    "- Base\n",
    "    - `lr_pred_y_tb`: $P_{\\text{label=1}}=0.43, R_{\\text{label=1}}=0.85$ \n",
    "    - `LDA_pred_y_tb`: $P_{\\text{label=1}}=0.43, R_{\\text{label=1}}=0.88$  \n",
    "    - `xg_pred_y_tb`: $P_{\\text{label=1}}=0.43, R_{\\text{label=1}}=0.85$ \n",
    "- Trustworthy\n",
    "    - `lr_pred_y` : $P_{\\text{label=1}}=0.81, R_{\\text{label=1}}=0.11$ \n",
    "    - `rfc_pred_y` : $P_{\\text{label=1}}=0.76, R_{\\text{label=1}}=0.28$ \n",
    "    - `clf_pred_y`: $P_{\\text{label=1}}=1.0, R_{\\text{label=1}}=0.02$ \n",
    "    - `clf_pred_y_t`: $P_{\\text{label=1}}=0.89, R_{\\text{label=1}}=0.07$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------------LDA+lr-------------------\nconfusion matrix\n[[1108  128]\n [  13   96]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.727\n\n\n-------------------LDA+rfc-------------------\nconfusion matrix\n[[1108  128]\n [  13   96]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.727\n\n\n-------------------LDA+SVM-------------------\nconfusion matrix\n[[1108  128]\n [  13   96]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.727\n\n\n-------------------LDA+rfc+lr+SVM-------------------\nconfusion matrix\n[[1108  128]\n [  13   96]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.881\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.727\n\n\n"
    }
   ],
   "source": [
    "print('-------------------LDA+lr-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, lr_pred_y | LDA_pred_y_tb)\n",
    "\n",
    "print('-------------------LDA+rfc-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, rfc_pred_y | LDA_pred_y_tb)\n",
    "\n",
    "print('-------------------LDA+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, clf_pred_y | LDA_pred_y_tb)\n",
    "\n",
    "print('-------------------LDA+rfc+lr+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, clf_pred_y | lr_pred_y | rfc_pred_y | LDA_pred_y_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------------XG+lr-------------------\nconfusion matrix\n[[1111  125]\n [  16   93]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.711\n\n\n-------------------XG+rfc-------------------\nconfusion matrix\n[[1111  125]\n [  16   93]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.711\n\n\n-------------------XG+SVM-------------------\nconfusion matrix\n[[1111  125]\n [  16   93]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.711\n\n\n-------------------XG+rfc+lr+SVM-------------------\nconfusion matrix\n[[1111  125]\n [  16   93]]\n--summary[label=1]--\nprecision:0.427\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.895\nF2-score:0.711\n\n\n"
    }
   ],
   "source": [
    "print('-------------------XG+lr-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, lr_pred_y | xg_pred_y_tb)\n",
    "\n",
    "print('-------------------XG+rfc-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, rfc_pred_y | xg_pred_y_tb)\n",
    "\n",
    "print('-------------------XG+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, clf_pred_y | xg_pred_y_tb)\n",
    "\n",
    "print('-------------------XG+rfc+lr+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, lr_pred_y | rfc_pred_y | clf_pred_y | xg_pred_y_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------------lr+rfc-------------------\nconfusion matrix\n[[1112  124]\n [  15   94]]\n--summary[label=1]--\nprecision:0.431\nrecall:0.862\nsupport:None\n--------------------\naccuracy: 0.897\nF2-score:0.719\n\n\n-------------------lr+SVM-------------------\nconfusion matrix\n[[1112  124]\n [  16   93]]\n--summary[label=1]--\nprecision:0.429\nrecall:0.853\nsupport:None\n--------------------\naccuracy: 0.896\nF2-score:0.712\n\n\n-------------------lr+rfc+SVM-------------------\nconfusion matrix\n[[1112  124]\n [  15   94]]\n--summary[label=1]--\nprecision:0.431\nrecall:0.862\nsupport:None\n--------------------\naccuracy: 0.897\nF2-score:0.719\n\n\n"
    }
   ],
   "source": [
    "print('-------------------lr+rfc-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, rfc_pred_y | lr_pred_y_tb)\n",
    "\n",
    "print('-------------------lr+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, clf_pred_y | lr_pred_y_tb)\n",
    "\n",
    "print('-------------------lr+rfc+SVM-------------------')\n",
    "Cp.eval_metric(Cp.y_test_tb, rfc_pred_y | clf_pred_y | lr_pred_y_tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, these *trustworthy information* seem to have been covered already by the parties with good coverage.\n",
    "\n",
    "# 5. Conclusion \n",
    "\n",
    "Given the current dataset, using LDA on `0:n_classes-1[balanced]` gives the best result (precision:0.429, recall:0.881, accuracy: 0.895, F2-score:0.727) so far. Modles like XGBosst and linear regression using the same embedding gives a similar result. This suggests that the model has tried to extract as much as the infomration as they can. And for future work more domain-specific and fine-grained feature engineering is needed to further improve the result.\n",
    "\n",
    "We also experimented with two proposed voting mechanisms, but both failed to improve the result given the information is largely covered by the mentioned three models. For future work, one potential appraoch is to perform voting using part of the data following a similar idea like the cross-validation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}